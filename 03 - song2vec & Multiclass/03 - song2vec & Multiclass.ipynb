{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#  MelodyMaster\n",
    "## Notebook03 - song2vec & Multiclass\n",
    "### Idan Kashani & Or Raphael Bidusa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shalom again!\n",
    "Today we will examine another representation of the data - song2vec, based on word2vec representation.\n",
    "We will use this representation with all sorts of different model, hoping to get a better result than last time with our simple knn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import math\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the dataset and extracting the vocabulary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (8496, 6)\n",
      "Vocabulary length is: 62178\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../train.csv')\n",
    "print(f'train shape: {train_df.shape}')\n",
    "train_df['lyrics_as_list'] = train_df['lyrics'].map(lambda l: set(ast.literal_eval(str(l)))) #Why set?\n",
    "vocabulary = list(sorted(set.union(*train_df['lyrics_as_list'].tolist())))\n",
    "train_df['lyrics_as_list'] = train_df['lyrics'].map(lambda l: ast.literal_eval(str(l)))\n",
    "print(f\"Vocabulary length is: {len(vocabulary)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Song2Vec\n",
    "The Song2Vec representation (s2v from now) is based on the [word2vec](https://en.wikipedia.org/wiki/Word2vec) representation for words - a representation that relies on context.\n",
    "Training a word2vec model in Hebrew is not an easy task - it requires en enormous datasets and a lot of computing power and therefore we shall use an already trained model.\n",
    "We are using the [Ronshm](https://github.com/Ronshm/hebrew-word2vec) model, based on the entire Hebrew-Wikipedia site.\n",
    "The tokenization of this model is a bit different - the model separates nouns, adjectives and verbs and marks them with \"NN_\", \"VB_\" and \"JJ_\", we have decided to remove these marks to match our tokenization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "with open('../words_list_w2v.txt',encoding='utf-8') as f:\n",
    "    words = f.read().split('\\n')\n",
    "    # Removing the last word - an empty word\n",
    "    words.pop()\n",
    "vectors = np.load('../words_vectors_w2v.npy')\n",
    "\n",
    "words = [w[3:] if len(w)>3 and w[:3] in ['NN_','VB_','JJ_'] else w for w in words]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The word `שוטה` for example can be all 3, a noun, a verb and an adjective and therefore has 3 entries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word שוטה has 3 entries\n",
      "There are 4123 types with multiple entries\n"
     ]
    }
   ],
   "source": [
    "print(f\"The word שוטה has {words.count('שוטה')} entries\")\n",
    "from collections import defaultdict\n",
    "\n",
    "def list_duplicates(seq):\n",
    "    tally = defaultdict(list)\n",
    "    for i,item in enumerate(seq):\n",
    "        tally[item].append(i)\n",
    "    return ((key,locs) for key,locs in tally.items()\n",
    "            if len(locs)>1)\n",
    "\n",
    "dups_indx = [dup for dup in sorted(list_duplicates(words))]\n",
    "print(f\"There are {len(dups_indx)} types with multiple entries\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will merge those together, using the mean for the 3 entries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "words = list(OrderedDict.fromkeys(words))\n",
    "vectors_without_dups = vectors.copy()\n",
    "to_delete = []\n",
    "for d in dups_indx:\n",
    "    indices = sorted(d[1])\n",
    "    vectors_without_dups[indices[0]] = np.mean(vectors[indices])\n",
    "    to_delete = to_delete + indices[1:]\n",
    "vectors = np.delete(vectors_without_dups, to_delete, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a vocabulary of 340,419(!!) words, with corresponding 340,419 vectors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340419\n",
      "340419\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(len(vectors))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will create a way for to jump between the two representations, words and vectors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "w2v = dict(zip(words,vectors))\n",
    "v2w_rep = dict(zip([tuple(v) for v in vectors],words))\n",
    "def v2w(vector):\n",
    "    return v2w_rep[tuple(vector)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a dictionary for word->vector function and a method for the vector->word function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.285577 -2.40504  -0.247569  1.565358 -0.507429  0.421352  2.919839\n",
      "  0.175767 -0.81715   4.027268 -4.426804 -0.335856  1.37266  -2.470423\n",
      " -0.637528 -0.625319 -0.387694 -0.377863 -2.823385  0.453176 -0.18862\n",
      " -1.135968  1.384955  1.184353 -1.846833 -1.811182  2.862987  0.043025\n",
      " -0.208302  0.839443  0.249148 -0.77285  -2.413144  1.783451  2.926803\n",
      " -3.261037  0.36823  -3.402674  0.538493 -1.489707 -1.453904 -1.631255\n",
      "  2.344507 -1.803826 -0.740482  1.634151 -0.077221  0.617151  0.294225\n",
      "  1.010752 -1.132112  0.357843 -1.024291 -1.490058  0.439202 -3.380302\n",
      "  1.791306 -3.620549  0.068354 -0.148103 -1.801437  0.181857  3.369811\n",
      "  4.313795  0.721022  0.792466  2.422217  2.32172   0.197274 -2.948433\n",
      "  1.928675  0.277213  0.733989 -1.983691  2.088614  1.454925  2.900067\n",
      "  3.587338  3.282094  0.349965 -2.046078 -1.244647 -0.144329  1.375046\n",
      "  1.199163 -0.049973  0.327037 -2.425939  0.120854  2.901864  2.422603\n",
      " -0.95862   0.298806  1.730013 -1.094935 -0.845992  2.312083 -3.531979\n",
      "  1.801935 -2.222774]\n",
      "ישראל\n"
     ]
    }
   ],
   "source": [
    "ahavti_vec = w2v[\"ישראל\"]\n",
    "print(ahavti_vec)\n",
    "print(v2w(ahavti_vec))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The power of word2vec\n",
    "With word2vec representation each word is represented by a 100d vector.\n",
    "In order to demonstrate the meaning of closeness in this vector space we have two methods, one for finding the closest word in the vector space and one for finding the k-closest-vectors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(vectors)\n",
    "\n",
    "def closest_word(vector):\n",
    "    return words[tree.query(vector, k=1)[1]]\n",
    "\n",
    "def k_closest_words(vector, k=5):\n",
    "    distances, close_words = tree.query(vector, k=k)\n",
    "    return [(words[w], d) for w, d in zip(list(close_words.astype(int)), distances)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One interesting result is looking at the closest vectors for the representation of Germany as a vector.\n",
    "We get a list of countries with both geographic and historical proximity like Austria, Switzerland and even Prussia."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "[('גרמניה', 0.0),\n ('אוסטריה', 9.436663490929567),\n ('שווייץ', 10.70911817768223),\n ('פרוסיה', 10.974586621357817),\n ('פולין', 11.275983929305372),\n ('הולנד', 11.324757442402465),\n ('צרפת', 11.344306222048795),\n (\"צ'כוסלובקיה\", 11.5207771481726),\n ('הונגריה', 11.54691985215105),\n ('רוסיה', 11.644340376521805)]"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_closest_words(w2v[\"גרמניה\"],k=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One very interesting test is the analogy test.\n",
    "Using vector subtraction we can get the \"vectorised difference\" between two words - the relation between them.\n",
    "For example, subtracting between \"England\" and \"London\" will give us a relation vector of \"Capital City\".\n",
    "Adding this \"relation vector\" to a different word and then finding the closest vector to this sum can sometimes give us the corresponding analogy for this word.\n",
    "Let's try to add the relation vector of \"Capital City\" to France, Belgium, Japan or Germany."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "# x to y is like a to ?\n",
    "def analogy(x,y,a):\n",
    "    return w2v[y]-w2v[x]+w2v[a]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "פריז\n",
      "בריסל\n",
      "טוקיו\n",
      "ברלין\n"
     ]
    }
   ],
   "source": [
    "print(closest_word(analogy(\"אנגליה\", \"לונדון\", \"צרפת\")))\n",
    "print(closest_word(analogy(\"אנגליה\", \"לונדון\", \"בלגיה\")))\n",
    "print(closest_word(analogy(\"אנגליה\", \"לונדון\", \"יפן\")))\n",
    "print(closest_word(analogy(\"אנגליה\", \"לונדון\", \"גרמניה\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model can also find gendered relations:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "נסיכה\n",
      "מושלת\n",
      "ביישנית\n",
      "מוזיקאית\n"
     ]
    }
   ],
   "source": [
    "print(closest_word(analogy(\"מלך\", \"מלכה\", \"נסיך\")))\n",
    "print(closest_word(analogy(\"מלך\", \"מלכה\", \"מושל\")))\n",
    "print(closest_word(analogy(\"מלך\", \"מלכה\", \"ביישן\")))\n",
    "print(closest_word(analogy(\"מלך\", \"מלכה\", \"מוזיקאי\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For song2vec representation we will try two pooling methods.\n",
    "Mean-Pooling - taking the mean vector of all the words in the song.\n",
    "Max-Pooling - for each entry in the 100d vector - taking the max of all words in the song.\n",
    "For words which do not appear in the dataset - we will ignore them completely."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def song2vec_mean(song):\n",
    "    return np.mean([w2v[w] for w in song if w in words],axis=0)\n",
    "\n",
    "def song2vec_max(song):\n",
    "    return np.max([w2v[w] for w in song if w in words], axis=0)\n",
    "\n",
    "words_set = set(words)\n",
    "train_df['song2vec_mean'] = train_df['lyrics_as_list'].map(lambda l: np.mean([w2v[w] for w in l if w in words_set],axis=0))\n",
    "train_df = train_df.dropna()\n",
    "train_df['song2vec_max'] = train_df['lyrics_as_list'].map(lambda l: np.max([w2v[w] for w in l if w in words_set],axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiClass\n",
    "We will examine the power of the new representation with all different kinds of models - but this time instead of one-vs-all we will try MultiClass - the true task of this project.\n",
    "We will try different sets of learning algorithms, for each set of algorithms we will find the best model using CV.\n",
    "We will once again use the f1 score for comparing between the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## kNN - revisited"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Mean Pooling:\n",
      "Best Params: {'n_neighbors': 46}\n",
      "Best f1 score for validation: 6.60377358490566\n",
      "The corresponding train f1 score: 9.971584699453553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X = np.array([np.array(w) for w in train_df['song2vec_mean']])\n",
    "y = np.array(train_df['artist'])\n",
    "knn = KNeighborsClassifier(metric='cosine')\n",
    "param_grid = {'n_neighbors': np.arange(1, 151, 15)}\n",
    "cv = StratifiedShuffleSplit(n_splits=3, random_state=42)\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=cv,scoring=\"f1_micro\",error_score=\"raise\",return_train_score=True)\n",
    "knn_mean = knn_gscv.fit(X, y)\n",
    "print(\"kNN Mean Pooling:\")\n",
    "print(f\"Best Params: {knn_mean.best_params_}\")\n",
    "print(f\"Best f1 score for validation: {100*knn_mean.best_score_}\")\n",
    "print(f\"The corresponding train f1 score: {100*knn_mean.cv_results_['mean_train_score'][knn_mean.best_index_]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Max Pooling:\n",
      "Best Params: {'n_neighbors': 91}\n",
      "Best f1 score for validation: 5.031446540880503\n",
      "The corresponding train f1 score: 7.042622950819672\n"
     ]
    }
   ],
   "source": [
    "X = np.array([np.array(w) for w in train_df['song2vec_max']])\n",
    "knn = KNeighborsClassifier(metric='cosine')\n",
    "param_grid = {'n_neighbors': np.arange(1, 151, 15)}\n",
    "cv = StratifiedShuffleSplit(n_splits=3, random_state=42)\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=cv,scoring=\"f1_micro\",error_score=\"raise\",return_train_score=True)\n",
    "knn_max = knn_gscv.fit(X, y)\n",
    "print(\"kNN Max Pooling:\")\n",
    "print(f\"Best Params: {knn_max.best_params_}\")\n",
    "print(f\"Best f1 score for validation: {100*knn_max.best_score_}\")\n",
    "print(f\"The corresponding train f1 score: {100*knn_max.cv_results_['mean_train_score'][knn_max.best_index_]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV 1/3] END C=0.01, gamma=1e-09;, score=(train=0.041, test=0.041) total time=   6.9s\n",
      "[CV 2/3] END C=0.01, gamma=1e-09;, score=(train=0.041, test=0.041) total time=   6.3s\n",
      "[CV 3/3] END C=0.01, gamma=1e-09;, score=(train=0.041, test=0.041) total time=   6.7s\n",
      "[CV 1/3] END C=0.01, gamma=1e-05;, score=(train=0.041, test=0.041) total time=   6.6s\n",
      "[CV 2/3] END C=0.01, gamma=1e-05;, score=(train=0.041, test=0.041) total time=   6.7s\n",
      "[CV 3/3] END C=0.01, gamma=1e-05;, score=(train=0.041, test=0.041) total time=   6.7s\n",
      "[CV 1/3] END C=0.01, gamma=0.1;, score=(train=0.041, test=0.041) total time=   7.7s\n",
      "[CV 2/3] END C=0.01, gamma=0.1;, score=(train=0.041, test=0.041) total time=   7.9s\n",
      "[CV 3/3] END C=0.01, gamma=0.1;, score=(train=0.041, test=0.041) total time=   7.5s\n",
      "[CV 1/3] END C=0.01, gamma=1000.0;, score=(train=0.041, test=0.041) total time=  15.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [202]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m cv \u001B[38;5;241m=\u001B[39m StratifiedShuffleSplit(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m43\u001B[39m)\n\u001B[0;32m      8\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(clf, param_grid, cv\u001B[38;5;241m=\u001B[39mcv,scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1_micro\u001B[39m\u001B[38;5;124m\"\u001B[39m,error_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,return_train_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m svm_mean \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSVM Mean Pooling:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Params: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msvm_mean\u001B[38;5;241m.\u001B[39mbest_params_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    871\u001B[0m     )\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1375\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1374\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1375\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    819\u001B[0m         )\n\u001B[0;32m    820\u001B[0m     )\n\u001B[1;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    844\u001B[0m     )\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:1046\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1044\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1046\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1047\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1050\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:711\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    709\u001B[0m     score_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time \u001B[38;5;241m-\u001B[39m fit_time\n\u001B[0;32m    710\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_train_score:\n\u001B[1;32m--> 711\u001B[0m         train_scores \u001B[38;5;241m=\u001B[39m \u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    714\u001B[0m     total_time \u001B[38;5;241m=\u001B[39m score_time \u001B[38;5;241m+\u001B[39m fit_time\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001B[0m, in \u001B[0;36m_score\u001B[1;34m(estimator, X_test, y_test, scorer, error_score)\u001B[0m\n\u001B[0;32m    765\u001B[0m         scores \u001B[38;5;241m=\u001B[39m scorer(estimator, X_test)\n\u001B[0;32m    766\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 767\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[43mscorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m error_score \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:219\u001B[0m, in \u001B[0;36m_BaseScorer.__call__\u001B[1;34m(self, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, estimator, X, y_true, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \n\u001B[0;32m    199\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m        Score function applied to prediction of estimator on X.\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 219\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_cached_call\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:261\u001B[0m, in \u001B[0;36m_PredictScorer._score\u001B[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_score\u001B[39m(\u001B[38;5;28mself\u001B[39m, method_caller, estimator, X, y_true, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001B[39;00m\n\u001B[0;32m    235\u001B[0m \n\u001B[0;32m    236\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;124;03m        Score function applied to prediction of estimator on X.\u001B[39;00m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 261\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmethod_caller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sign \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_func(\n\u001B[0;32m    264\u001B[0m             y_true, y_pred, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kwargs\n\u001B[0;32m    265\u001B[0m         )\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:71\u001B[0m, in \u001B[0;36m_cached_call\u001B[1;34m(cache, estimator, method, *args, **kwargs)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;124;03m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(estimator, method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cache[method]\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:810\u001B[0m, in \u001B[0;36mBaseSVC.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    808\u001B[0m     y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    809\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 810\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    811\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39masarray(y, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mintp))\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:435\u001B[0m, in \u001B[0;36mBaseLibSVM.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    433\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_for_predict(X)\n\u001B[0;32m    434\u001B[0m predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse_predict \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dense_predict\n\u001B[1;32m--> 435\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\bidusa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:454\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    447\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX.shape[1] = \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m should be equal to \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    448\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe number of samples at training time\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    449\u001B[0m             \u001B[38;5;241m%\u001B[39m (X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    450\u001B[0m         )\n\u001B[0;32m    452\u001B[0m svm_type \u001B[38;5;241m=\u001B[39m LIBSVM_IMPL\u001B[38;5;241m.\u001B[39mindex(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_impl)\n\u001B[1;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msupport_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msupport_vectors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_n_support\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dual_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_intercept_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_probA\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_probB\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    465\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    466\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    469\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X = np.array([np.array(w) for w in train_df['song2vec_mean']])\n",
    "C_range = np.logspace(-2, 10, 4)\n",
    "gamma_range = np.logspace(-9, 3, 4)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "clf = SVC(kernel='rbf')\n",
    "cv = StratifiedShuffleSplit(n_splits=3, random_state=43)\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=cv,scoring=\"f1_micro\",error_score=\"raise\",return_train_score=True,verbose=3)\n",
    "svm_mean = grid_search.fit(X, y)\n",
    "print(\"SVM Mean Pooling:\")\n",
    "print(f\"Best Params: {svm_mean.best_params_}\")\n",
    "print(f\"Best f1 score for validation: {100*svm_mean.best_score_}\")\n",
    "print(f\"The corresponding train f1 score: {100*svm_mean.cv_results_['mean_train_score'][svm_mean.best_index_]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-02 1.e+01 1.e+04 1.e+07 1.e+10]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
