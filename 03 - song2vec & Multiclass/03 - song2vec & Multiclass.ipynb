{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#  MelodyMaster\n",
    "## Notebook03 - song2vec & Multiclass\n",
    "### Idan Kashani & Or Raphael Bidusa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shalom again!\n",
    "Today we will examine another representation of the data - song2vec, based on word2vec representation.\n",
    "We will use this representation with all sorts of different model, hoping to get a better result than last time with our simple knn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import ast\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the dataset and getting the vocabulary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (8496, 6)\n",
      "Vocabulary length is: 62178\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../train.csv')\n",
    "print(f'train shape: {train_df.shape}')\n",
    "train_df['lyrics_as_list'] = train_df['lyrics'].map(lambda l: set(ast.literal_eval(str(l)))) #Why set?\n",
    "vocabulary = list(sorted(set.union(*train_df['lyrics_as_list'].tolist())))\n",
    "train_df['lyrics_as_list'] = train_df['lyrics'].map(lambda l: ast.literal_eval(str(l)))\n",
    "print(f\"Vocabulary length is: {len(vocabulary)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "with open('../words_list_w2v.txt',encoding='utf-8') as f:\n",
    "    words = f.read().split('\\n')\n",
    "    # Removing the last word - an empty word\n",
    "    words.pop()\n",
    "vectors = np.load('../words_vectors_w2v.npy')\n",
    "\n",
    "words = [w[3:] if len(w)>3 and w[:3] in ['NN_','VB_','JJ_'] else w for w in words]\n",
    "\n",
    "for w in words:\n",
    "    if len(w) > 3:\n",
    "        if w[:3] == \"NN_\" or w[:3] == \"VB_\" or w[:3] == \"JJ_\":\n",
    "            print(w)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(words.count('פסיכותרפיסט'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4123 types with multiple entries\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def list_duplicates(seq):\n",
    "    tally = defaultdict(list)\n",
    "    for i,item in enumerate(seq):\n",
    "        tally[item].append(i)\n",
    "    return ((key,locs) for key,locs in tally.items()\n",
    "            if len(locs)>1)\n",
    "\n",
    "dups_indx = [dup for dup in sorted(list_duplicates(words))]\n",
    "print(f\"There are {len(dups_indx)} types with multiple entries\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "words = list(OrderedDict.fromkeys(words))\n",
    "vectors_without_dups = vectors.copy()\n",
    "to_delete = []\n",
    "for d in dups_indx:\n",
    "    indices = sorted(d[1])\n",
    "    vectors_without_dups[indices[0]] = np.mean(vectors[indices])\n",
    "    to_delete = to_delete + indices[1:]\n",
    "vectors = np.delete(vectors_without_dups, to_delete, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340419\n",
      "340419\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(len(vectors))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "w2v = dict(zip(words,vectors))\n",
    "v2w_rep = dict(zip([tuple(v) for v in vectors],words))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.047849 -0.237195  0.296635 -0.014212  0.022151  0.172562 -0.081755\n",
      "  0.131053 -0.049191  0.166546  0.046406  0.112231 -0.065383 -0.154182\n",
      "  0.11132   0.357974  0.056559 -0.197837  0.122658  0.065558 -0.176146\n",
      "  0.124626  0.266774 -0.331449  0.055231 -0.08458   0.033744  0.081236\n",
      "  0.169651  0.221381  0.004441 -0.244207  0.080133  0.244274 -0.09737\n",
      " -0.035503  0.162789  0.126568  0.081791 -0.083357  0.059758  0.087832\n",
      "  0.079024  0.146633  0.105375  0.160128 -0.129235 -0.158333  0.173166\n",
      "  0.037226 -0.071079  0.01272  -0.014435 -0.002203  0.242982 -0.220937\n",
      "  0.001111 -0.070437  0.194238  0.162719  0.067988 -0.159687  0.061967\n",
      "  0.025371 -0.174582  0.178798  0.029152  0.025532  0.016066  0.246695\n",
      " -0.056776 -0.389847 -0.053492 -0.16045  -0.321974 -0.153765  0.041302\n",
      " -0.010492 -0.284652  0.126697  0.068541  0.001509 -0.023024 -0.059568\n",
      "  0.10348   0.244634  0.061512 -0.074103  0.096155  0.170907 -0.092507\n",
      "  0.150437 -0.040386  0.103263  0.153118  0.073103 -0.051595  0.286848\n",
      " -0.036053 -0.136423]\n",
      "אהבתיה\n"
     ]
    }
   ],
   "source": [
    "def v2w(vector):\n",
    "    return v2w_rep[tuple(vector)]\n",
    "\n",
    "ahavti_vec = w2v[\"אהבתיה\"]\n",
    "print(ahavti_vec)\n",
    "print(v2w(ahavti_vec))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(vectors)\n",
    "\n",
    "def closest_word(vector):\n",
    "    return words[tree.query(vector, k=1)[1]]\n",
    "\n",
    "def k_closest_words(vector, k=5):\n",
    "    distances, close_words = tree.query(vector, k=k)\n",
    "    return [(words[w], d) for w, d in zip(list(close_words.astype(int)), distances)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def analogy(x,y,a):\n",
    "    return w2v[y]-w2v[x]+w2v[a]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "פריז\n",
      "נסיכה\n"
     ]
    }
   ],
   "source": [
    "print(closest_word(analogy(\"אנגליה\", \"לונדון\", \"צרפת\")))\n",
    "print(closest_word(analogy(\"מלך\", \"מלכה\", \"נסיך\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "[('גרמניה', 0.0),\n ('אוסטריה', 9.436663490929567),\n ('שווייץ', 10.70911817768223),\n ('פרוסיה', 10.974586621357817),\n ('פולין', 11.275983929305372),\n ('הולנד', 11.324757442402465),\n ('צרפת', 11.344306222048795),\n (\"צ'כוסלובקיה\", 11.5207771481726),\n ('הונגריה', 11.54691985215105),\n ('רוסיה', 11.644340376521805),\n ('פינלנד', 11.71177972528518),\n ('איטליה', 11.92222299772081),\n ('ברלין', 11.978732594655956),\n ('בלגיה', 12.067913401246797)]"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_closest_words(w2v[\"גרמניה\"],k=14)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "def song2vec_mean(song):\n",
    "    print(len([w for w in song if w in words]))\n",
    "    return np.mean([w2v[w] for w in song if w in words],axis=0)\n",
    "\n",
    "def song2vec_max(song):\n",
    "    return np.max([w2v[w] for w in song if w in words], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "[('לחייך', 3.8804646630631243), ('חידלון', 4.019876706009065), ('דבר-מה', 4.047996808217183), ('מגעיל', 4.144055661598788), ('אמך', 4.200752824215914)]\n",
      "[('סינית', 28.152123957105488), ('יפנית', 28.429831888516166), ('מושלמת', 28.441094344656186), ('נפוצה', 28.478048915127026), ('טהורה', 28.63744286765999)]\n"
     ]
    }
   ],
   "source": [
    "lo_yachol = train_df.query(\"song_name == 'מתי נתנשק'\")[\"lyrics_as_list\"].tolist()[0]\n",
    "print(k_closest_words(song2vec_mean(lo_yachol)))\n",
    "print(k_closest_words(song2vec_max(lo_yachol)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "words_set = set(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "train_df['song2vec_mean'] = train_df['lyrics_as_list'].map(lambda l: np.mean([w2v[w] for w in l if w in words_set],axis=0))\n",
    "train_df = train_df.dropna()\n",
    "train_df['song2vec_max'] = train_df['lyrics_as_list'].map(lambda l: np.max([w2v[w] for w in l if w in words_set],axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
